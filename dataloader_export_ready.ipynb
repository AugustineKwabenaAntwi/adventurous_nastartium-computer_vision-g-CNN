{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d6cef2f-bf8e-41c8-b5a1-74212ed3bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pathlib\n",
    "import csv\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "#from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "#from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "#import torch.nn as nn\n",
    "#import torch.optim as optim\n",
    "\n",
    "#from torchvision.utils import make_grid\n",
    "import torchvision.transforms as transforms\n",
    "#from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8695af52-a4d6-4e99-b8b9-46c15918aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE FROM MOBIN, related to this task\n",
    "# class CustomImageDataset(Dataset):\n",
    "#     def __init__(self, root_dir, transform=None):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             root_dir (string): Directory with all the subdirectories containing images and CSV files.\n",
    "#             transform (callable, optional): Optional transform to be applied on a sample.\n",
    "#         \"\"\"\n",
    "#         self.root_dir = root_dir\n",
    "#         self.transform = transform\n",
    "#         self.image_paths = []\n",
    "#         self.labels = []\n",
    "#         self._load_data()\n",
    "\n",
    "#     def _load_data(self):\n",
    "#         # Iterate over each subdirectory\n",
    "#         for sub_dir in os.listdir(self.root_dir):\n",
    "#             sub_dir_path = os.path.join(self.root_dir, sub_dir)\n",
    "#             if os.path.isdir(sub_dir_path):\n",
    "#                 # Load the CSV file\n",
    "#                 csv_file = [file for file in os.listdir(sub_dir_path) if file.endswith('.csv')]\n",
    "#                 if len(csv_file) == 1:\n",
    "#                     csv_path = os.path.join(sub_dir_path, csv_file[0])\n",
    "#                     df = pd.read_csv(csv_path)\n",
    "\n",
    "#                     # Iterate over each row in the CSV\n",
    "#                     for _, row in df.iterrows():\n",
    "#                         image_path = os.path.join(sub_dir_path, row['filename'])\n",
    "#                         label = row['label']\n",
    "#                         if os.path.isfile(image_path):\n",
    "#                             self.image_paths.append(image_path)\n",
    "#                             self.labels.append(label)\n",
    "#                 else:\n",
    "#                     print(f\"Error: More than one or no CSV files found in {sub_dir_path}\")\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if torch.is_tensor(idx):\n",
    "#             idx = idx.tolist()\n",
    "\n",
    "#         img_path = self.image_paths[idx]\n",
    "#         image = Image.open(img_path).convert('RGB')\n",
    "#         label = self.labels[idx]\n",
    "\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "\n",
    "#         return image, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68a24f83-72fa-4257-9f19-56de788cb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown `shuffle-spli and dataset constructor`\n",
    "def shuffle_and_split_data(X, y, seed, split_percent=0.2):\n",
    "  \"\"\"\n",
    "  Helper function to shuffle and split data, yoinked from W1D3 tutorial\n",
    "\n",
    "  Args:\n",
    "    X: torch.tensor\n",
    "      Input data\n",
    "    y: torch.tensor\n",
    "      Corresponding target variables\n",
    "    seed: int\n",
    "      Set seed for reproducibility\n",
    "\n",
    "  Returns:\n",
    "    X_test: torch.tensor\n",
    "      Test data [20% of X]\n",
    "    y_test: torch.tensor\n",
    "      Labels corresponding to above mentioned test data\n",
    "    X_train: torch.tensor\n",
    "      Train data [80% of X]\n",
    "    y_train: torch.tensor\n",
    "      Labels corresponding to above mentioned train data\n",
    "  \"\"\"\n",
    "  # Set seed for reproducibility\n",
    "  torch.manual_seed(seed)\n",
    "  # Number of samples\n",
    "  N = X.shape[0]\n",
    "  # Shuffle data\n",
    "  shuffled_indices = torch.randperm(N)   # Get indices to shuffle data, could use torch.randperm\n",
    "  X = X[shuffled_indices]\n",
    "  y = y[shuffled_indices]\n",
    "\n",
    "  # Split data into train/test\n",
    "  test_size = int(split_percent * N)    # Assign test datset size using 20% of samples\n",
    "  X_test = X[:test_size]\n",
    "  y_test = y[:test_size]\n",
    "  X_train = X[test_size:]\n",
    "  y_train = y[test_size:]\n",
    "\n",
    "  return X_test, y_test, X_train, y_train\n",
    "\n",
    "\n",
    "def get_datasets(images_pathfull, image_name_prefix, CSVlabels_pathfull, N_samples, percent_test, percent_valid, transform=None):\n",
    "    \"\"\"\n",
    "    Helper function to get train, test, and validation datasets, do note that the images come out rescaled to [0,1]\n",
    "\n",
    "    Args:\n",
    "        images_pathfull: string\n",
    "            path to the folder that includes all the images\n",
    "        image_name_prefix: string\n",
    "            the first part of the image name, with full filename being image_name_prefix+\"INTEGER\"+\".png\"\n",
    "        CSVlabels_pathfull: string\n",
    "            path to a .CSV file that includes all the labels\n",
    "        N_samples: integer\n",
    "            total number of samples to procure\n",
    "        transform: torch.transform\n",
    "            additional transformations to apply to images\n",
    "        percent_test: float\n",
    "            ratio of N_samples to be moved to test dataset, test dataset size is N_samples*percent_test\n",
    "        percent_valid: float\n",
    "            ratio of N_samples to be moved to valid dataset, valid dataset size is N_samples*percent_valid\n",
    "      \n",
    "    Returns:\n",
    "        train_data: torch.TensorDataset\n",
    "            train data, comes out shuffled, total number of samples = N_samples*(1-percent_test-percent_valid) \n",
    "        test_data: torch.TensorDataset\n",
    "            test data, comes out shuffled, total number of samples = N_samples*percent_test\n",
    "        valid_data: torch.TensorDataset\n",
    "            validation data, comes out shuffled, total number of samples = N_samples*percent_valid\n",
    "    \"\"\"  \n",
    "    #LABELS...\n",
    "    #load the labels\n",
    "    with open(images_pathfull, newline='') as csvfile:\n",
    "        CSVlabels = list(csv.reader(csvfile))\n",
    "    assert len(labels) >= N_samples\n",
    "    #take N_samples from the total dataset\n",
    "    shuffled_indices = torch.randperm(int(len(labels)))[:N_samples]\n",
    "    labels = [CSVlabels[i] for i in shuffled_indices]\n",
    "    #encode strings into numbers and store in a np array\n",
    "    #what follows is a very dumb implementation of the aforementioned\n",
    "    string_size=len(labels[0][0])\n",
    "    np_labels = np.empty((1,string_size))\n",
    "    for dat in labels:\n",
    "        i=0\n",
    "        temp = np.empty((1,string_size))\n",
    "        for char in dat[0]:\n",
    "            score = 4*(ord(char)-96) #get ascii code for char, rescale to 0-100\n",
    "            if score == -256: score = 0 #set spaces to 0s (otherwise, they end up very negative)\n",
    "            temp[0,i] = score\n",
    "            i+=1\n",
    "        np_labels = np.vstack((np_labels, temp))\n",
    "    np_labels = np_labels[1:,:]\n",
    "    #finally transform the labels to tensors\n",
    "    trans_totensor = transforms.ToTensor()\n",
    "    y_tensor = totensor_trans(np_labels)[0]\n",
    "\n",
    "    #IMAGES...\n",
    "    #prepare transforms, then load all the images  \n",
    "    trans_to_img = transforms.PILToTensor()\n",
    "    #load first image, then concat all the others\n",
    "    im = Image.open( os.path.join(images_pathfull, image_name_prefix + f\"{shuffled_indices[0]}.png\") )\n",
    "    im_tensor = 1.-trans_to_img(im).float()/255.\n",
    "    for i in shuffled_indices[1:]:\n",
    "        im = Image.open( os.path.join(images_pathfull, image_name_prefix + {i} + \".png\") )\n",
    "        im_tensor = torch.cat((im_tensor, 1.-trans_to_img(im).float()/255. ),0)\n",
    "    #apply additional transform is speficied\n",
    "    if transform != None: im_tensor=transform(im_tensor)\n",
    "        \n",
    "    #shuffle and split our data\n",
    "    X_test, y_test, X_train, y_train = shuffle_and_split_data( X=im_tensor, y=y_tensor, seed=SEED,\n",
    "                                                               split_percent=percent_test )\n",
    "    X_test, y_test, X_valid, y_valid = shuffle_and_split_data( X=X_test,    y=y_test, seed=SEED,\n",
    "                                                               split_percent= percent_valid/(1-percent_test) )\n",
    "   \n",
    "    \n",
    "    test_data =  TensorDataset(X_test,  y_test)\n",
    "    train_data = TensorDataset(X_train, y_train)\n",
    "    valid_data = TensorDataset(X_valid, y_valid)\n",
    "    return train_data, test_data, valid_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6bb336-ffd4-4231-8bb9-81ca9c96b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usage code example...\n",
    "\n",
    "train_data, test_data, valid_data = get_datasets(\n",
    "    images_pathfull=\"/home/workstation319/Desktop/python/NMA codes and stuffs/project/temp\", \n",
    "    image_name_prefix=\"base_img\", \n",
    "    CSVlabels_pathfull=\"/home/workstation319/Desktop/python/NMA codes and stuffs/project/labels.csv\", \n",
    "    N_samples=int(1e4), \n",
    "    percent_test=0.1, \n",
    "    percent_valid=0.2, \n",
    "    transform=None\n",
    ")\n",
    "# we should be able to use predefined torch dataloader:\n",
    "batch_size = 256\n",
    "g_seed = torch.Generator()\n",
    "g_seed.manual_seed(SEED)\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          drop_last=True,\n",
    "                          shuffle=True, \n",
    "                          worker_init_fn=seed_worker,\n",
    "                          generator=g_seed,\n",
    "                          )\n",
    "test_loader = DataLoader(test_data,\n",
    "                          batch_size=batch_size,\n",
    "                          drop_last=True,\n",
    "                          shuffle=True,\n",
    "                          worker_init_fn=seed_worker,\n",
    "                          generator=g_seed,\n",
    "                          )\n",
    "valid_loader = DataLoader(valid_data,\n",
    "                          batch_size=batch_size,\n",
    "                          drop_last=True,\n",
    "                          shuffle=True,\n",
    "                          worker_init_fn=seed_worker,\n",
    "                          generator=g_seed,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b923c1-4bb6-431c-afdd-017cc8126b40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NMA)",
   "language": "python",
   "name": "nma_python_ker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

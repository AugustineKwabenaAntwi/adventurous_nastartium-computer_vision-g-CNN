{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPxN/f5G0z3IM20k6/VYoPJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Imports\n","import pathlib\n","import csv\n","import os\n","import cv2\n","import torchvision.transforms as T\n","from torchvision.transforms import Lambda\n","\n","import random\n","import numpy as np\n","#from tqdm.auto import tqdm\n","from PIL import Image, ImageEnhance\n","\n","#from IPython.display import display\n","import matplotlib.pyplot as plt\n","\n","import torch\n","#import torch.nn as nn\n","#import torch.optim as optim\n","\n","#from torchvision.utils import make_grid\n","import torchvision.transforms as transforms\n","#from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader, TensorDataset"],"metadata":{"id":"3LcC586wdnUP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @markdown `shuffle-spli and dataset constructor`\n","def shuffle_and_split_data(X, y, seed, split_percent=0.2):\n","  \"\"\"\n","  Helper function to shuffle and split data, yoinked from W1D3 tutorial\n","\n","  Args:\n","    X: torch.tensor\n","      Input data\n","    y: torch.tensor\n","      Corresponding target variables\n","    seed: int\n","      Set seed for reproducibility\n","\n","  Returns:\n","    X_test: torch.tensor\n","      Test data [20% of X]\n","    y_test: torch.tensor\n","      Labels corresponding to above mentioned test data\n","    X_train: torch.tensor\n","      Train data [80% of X]\n","    y_train: torch.tensor\n","      Labels corresponding to above mentioned train data\n","  \"\"\"\n","  # Set seed for reproducibility\n","  torch.manual_seed(seed)\n","  # Number of samples\n","  N = X.shape[0]\n","  # Shuffle data\n","  shuffled_indices = torch.randperm(N)   # Get indices to shuffle data, could use torch.randperm\n","  X = X[shuffled_indices]\n","  y = y[shuffled_indices]\n","\n","  # Split data into train/test\n","  test_size = int(split_percent * N)    # Assign test datset size using 20% of samples\n","  X_test = X[:test_size]\n","  y_test = y[:test_size]\n","  X_train = X[test_size:]\n","  y_train = y[test_size:]\n","\n","  return X_test, y_test, X_train, y_train"],"metadata":{"id":"oUz2W0vRd-DH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Corruption functions\n","def add_salt_and_pepper_noise(image):\n","    row, col, _ = image.shape\n","    number_of_pixels = random.randint(300, 10000)\n","    for _ in range(number_of_pixels):\n","        y_coord = random.randint(0, row - 1)\n","        x_coord = random.randint(0, col - 1)\n","        image[y_coord, x_coord] = 255\n","    number_of_pixels = random.randint(300, 10000)\n","    for _ in range(number_of_pixels):\n","        y_coord = random.randint(0, row - 1)\n","        x_coord = random.randint(0, col - 1)\n","        image[y_coord, x_coord] = 0\n","    return image\n","\n","def add_pepper_noise(image):\n","    row, col, _ = image.shape\n","    number_of_pixels = random.randint(300, 10000)\n","    for _ in range(number_of_pixels):\n","        y_coord = random.randint(0, row - 1)\n","        x_coord = random.randint(0, col - 1)\n","        image[y_coord, x_coord] = 0\n","    return image\n","\n","def add_salt_noise(image):\n","    row, col, _ = image.shape\n","    number_of_pixels = random.randint(300, 50000)\n","    for _ in range(number_of_pixels):\n","        y_coord = random.randint(0, row - 1)\n","        x_coord = random.randint(0, col - 1)\n","        image[y_coord, x_coord] = 255\n","    return image\n","\n","def color_shift(image):\n","    img = np.array(image)\n","    h, w, c = img.shape\n","    rand_h = random.uniform(-0.2, 0.2)\n","    rand_s = random.uniform(0.8, 1.2)\n","    rand_v = random.uniform(0.8, 1.2)\n","    cs_matrix = np.array([[rand_h, .2, 0.4], [0, rand_s, .6], [0.7, 0, rand_v]])\n","    cs_matrix = np.clip(cs_matrix.astype(int), 0, 255)\n","    shifted = np.apply_along_axis(lambda a: cs_matrix.dot(a), 2, img)\n","    return Image.fromarray(shifted.astype(np.uint8))\n","\n","def adjust_contrast(image_path):\n","    image = cv2.imread(image_path)\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    Y = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)[:, :, 0]\n","    min_val = np.min(Y)\n","    max_val = np.max(Y)\n","    brightness = (max_val + min_val) / 2\n","    contrast = (max_val - min_val) / (max_val + min_val)\n","    brightness = brightness\n","    contrast = random.uniform(0.2, 3)\n","    image2 = cv2.convertScaleAbs(image_rgb, alpha=contrast, beta=brightness)\n","    return image2\n","\n","# Function to apply selected corruption\n","def apply_corruption(image, corruption_type):\n","    if corruption_type == 'salt_and_pepper':\n","        return add_salt_and_pepper_noise(image)\n","    elif corruption_type == 'pepper':\n","        return add_pepper_noise(image)\n","    elif corruption_type == 'salt':\n","        return add_salt_noise(image)\n","    elif corruption_type == 'color_shift':\n","        return color_shift(image)\n","    elif corruption_type == 'adjust_contrast':\n","        return adjust_contrast(image)\n","    else:\n","        return image\n","\n","# Modify the get_datasets function\n","def get_datasets(images_pathfull, image_name_prefix, CSVlabels_pathfull, N_samples, percent_test, percent_valid, transform=None, corruption_type=None):\n","    \"\"\"\n","    Helper function to get train, test, and validation datasets, do note that the images come out rescaled to [0,1]\n","\n","    Args:\n","        images_pathfull: string\n","            path to the folder that includes all the images\n","        image_name_prefix: string\n","            the first part of the image name, with full filename being image_name_prefix+\"INTEGER\"+\".png\"\n","        CSVlabels_pathfull: string\n","            path to a .CSV file that includes all the labels\n","        N_samples: integer\n","            total number of samples to procure\n","        transform: torch.transform\n","            additional transformations to apply to images\n","        percent_test: float\n","            ratio of N_samples to be moved to test dataset, test dataset size is N_samples*percent_test\n","        percent_valid: float\n","            ratio of N_samples to be moved to valid dataset, valid dataset size is N_samples*percent_valid\n","\n","    Returns:\n","        train_data: torch.TensorDataset\n","            train data, comes out shuffled, total number of samples = N_samples*(1-percent_test-percent_valid)\n","        test_data: torch.TensorDataset\n","            test data, comes out shuffled, total number of samples = N_samples*percent_test\n","        valid_data: torch.TensorDataset\n","            validation data, comes out shuffled, total number of samples = N_samples*percent_valid\n","    \"\"\"\n","    #LABELS...\n","    #load the labels\n","    with open(CSVlabels_pathfull, newline='') as csvfile:\n","        CSVlabels = list(csv.reader(csvfile))\n","    assert len(CSVlabels) >= N_samples\n","    shuffled_indices = torch.randperm(int(len(CSVlabels)))[:N_samples]\n","    labels = [CSVlabels[i] for i in shuffled_indices]\n","    string_size = len(labels[0][0])\n","    np_labels = np.empty((1, string_size))\n","    for dat in labels:\n","        i = 0\n","        temp = np.empty((1, string_size))\n","        for char in dat[0]:\n","            score = 4 * (ord(char) - 96)\n","            if score == -256: score = 0\n","            temp[0, i] = score\n","            i += 1\n","        np_labels = np.vstack((np_labels, temp))\n","    np_labels = np_labels[1:, :]\n","    totensor_trans = transforms.ToTensor()\n","    y_tensor = totensor_trans(np_labels)[0]\n","\n","    trans_to_img = transforms.PILToTensor()\n","    im = Image.open(os.path.join(images_pathfull, image_name_prefix + f\"{shuffled_indices[0]}.png\"))\n","    im_tensor = 1. - trans_to_img(im).float() / 255.\n","    im_tensor = torch.unsqueeze(im_tensor, 0)  # Add batch dimension\n","\n","    for i in shuffled_indices[1:]:\n","        im = Image.open(os.path.join(images_pathfull, image_name_prefix + f\"{i}.png\"))\n","        im_tensor = torch.cat((im_tensor, 1.-trans_to_img(im).float()/255. ),0)\n","    #apply additional transform is speficied\n","    if transform != None: im_tensor=transform(im_tensor)\n","\n","    if corruption_type:\n","        corrupted_images = []\n","        for img in im_tensor:\n","            corrupted_image = apply_corruption(img.numpy().transpose(1, 2, 0), corruption_type)\n","            corrupted_images.append(trans_to_img(Image.fromarray(corrupted_image.astype(np.uint8))).float() / 255.)\n","        im_tensor = torch.stack(corrupted_images)\n","\n","    #shuffle and split our data\n","    X_test, y_test, X_train, y_train = shuffle_and_split_data(X=im_tensor, y=y_tensor, seed=SEED, split_percent=percent_test)\n","    X_test, y_test, X_valid, y_valid = shuffle_and_split_data(X=X_test, y=y_test, seed=SEED, split_percent=percent_valid / (1 - percent_test))\n","\n","    test_data = TensorDataset(X_test, y_test)\n","    train_data = TensorDataset(X_train, y_train)\n","    valid_data = TensorDataset(X_valid, y_valid)\n","\n","    return train_data, test_data, valid_data\n","\n","# Usage example\n","\n","train_data, test_data, valid_data = get_datasets(\n","    images_pathfull=\"\",\n","    image_name_prefix=\"\",\n","    CSVlabels_pathfull=\"\",\n","    N_samples=int(1e4),\n","    percent_test=0.1,\n","    percent_valid=0.2,\n","    transform=None,\n","    corruption_type='salt_and_pepper'  # Choose the corruption type here\n",")\n","\n","# we should be able to use predefined torch dataloader:\n","batch_size = 256\n","g_seed = torch.Generator()\n","g_seed.manual_seed(SEED)\n","\n","train_loader = DataLoader(train_data,\n","                          batch_size=batch_size,\n","                          drop_last=True,\n","                          shuffle=True,\n","                          worker_init_fn=seed_worker,\n","                          generator=g_seed,\n","                          )\n","test_loader = DataLoader(test_data,\n","                          batch_size=batch_size,\n","                          drop_last=True,\n","                          shuffle=True,\n","                          worker_init_fn=seed_worker,\n","                          generator=g_seed,\n","                          )\n","valid_loader = DataLoader(valid_data,\n","                          batch_size=batch_size,\n","                          drop_last=True,\n","                          shuffle=True,\n","                          worker_init_fn=seed_worker,\n","                          generator=g_seed,\n","                          )\n"],"metadata":{"id":"FK7a8B7xXpWI"},"execution_count":null,"outputs":[]}]}